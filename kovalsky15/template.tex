\documentclass[serif,mathserif]{beamer}
\usepackage{etex}
\usepackage{amsmath, amsfonts, epsfig, xspace}
\usepackage{algorithm,algorithmic}
\usepackage{pstricks,pst-node}
\usepackage{multimedia}
\usepackage[normal,tight,center]{subfigure}
\usepackage{beamerthemesplit}
\usepackage{color}

\setlength{\subfigcapskip}{-.5em}
\usetheme{lankton-keynote}

\input{preamble.tex}

\author[Jiong Chen]{Jiong Chen}

\title[\hspace{2em}\insertframenumber/\inserttotalframenumber]{Large-Scale Bounded Distortion Mappings}

\date{October 28, 2015} %leave out for today's date to be insterted

% \institute{Zhejiang University}

\newcommand{\BOLD}[1]{\mathbf{#1}}
\newcommand{\BOLDG}[1]{\boldsymbol{#1}}
\newcommand{\PDIF}[2]{\frac{\partial #1}{\partial #2}}
\newcommand{\TODO}[1]{\textcolor{red}{#1}}
\newcommand{\argmin}{\operatornamewithlimits{arg\min}}
\DeclareMathOperator{\tr}{tr}
\DeclareMathOperator{\cond}{cond}
\DeclareMathOperator{\ST}{s.t.}
\DeclareMathOperator{\diag}{diag}

\definecolor{DARK}{RGB}{45, 33, 73}
\definecolor{LIGHT}{RGB}{119, 52, 106}
\definecolor{TEXTLIGHT}{RGB}{213, 207, 229}
\definecolor{TEXTDARK}{RGB}{66, 66, 66}
\definecolor{BULLET}{RGB}{179, 17, 102}
\definecolor{EM}{RGB}{179,17,102}

\begin{document}

\maketitle

\begin{frame}
 \frametitle{Problem statement}
 \begin{itemize}
  \item Given an initial map, compute a similar map whose differentials are \TODO{orientation preserving}
  and have \TODO{bounded condition number}.
  \Large
 \begin{equation*}
 \boxed{
  \begin{aligned}
    \min_{\BOLD{x}}~~&\|T\BOLD{x}-T\BOLD{x}_0\|_2  \\ 
    \ST \quad &A\BOLD{x} = \BOLD{b}\\
    &T_j\BOLD{x} \in \mathcal{D}_j
  \end{aligned}
 }
 \end{equation*}
 \large
 \item $\mathcal{D}_j=\mathcal{D}^K, j=1,2,\dots m$
 \begin{equation*}
  \det(D^K) \ge  0, \quad \cond(D^K) \le K
 \end{equation*}
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Problems statement}
 \begin{itemize}
  \item Nonlinear bounded distortion constraints $\Rightarrow$ difficult \& computationally demanding
  \item Numerical methods: first-order \& second order
  \item Second order: interior point solver \& Newton variants
  \item First order 
    \begin{itemize}
     \item[-] \textcolor{red}{Alternating optimization\,(Local/global, block descent)}
     \item[-] \textcolor{green!50!black}{Gauss-Newton for least squares}
    \end{itemize}
 \end{itemize}
\end{frame}

\begin{frame}
 \frametitle{Approach}
\end{frame}

\begin{frame}
 \frametitle{Algorithmic details}
 \begin{enumerate}
  \item \textit{\textbf{Project}} the lifted variable $\BOLD{z}_n=T\BOLD{x}_n$ onto $\mathcal{D}$, \textit{i.e.}, compute $\prod_\mathcal{D}(\BOLD{z}_n)$.
  \item Form $\mathcal{H}_n$ to be the \textbf{\textit{hyperplane}} orthogonal to the projection vector $\BOLD{z}_n-\prod_\mathcal{D}(\BOLD{z}_n)$.
  \item \textbf{\textit{Optimize}} with $(\BOLD{x}_*, \BOLD{x}_0)=(\BOLD{x}_{n+1}, \BOLD{x}_n)$.
 \end{enumerate}
\end{frame}

\begin{frame}
 \frametitle{Projection}
 \begin{itemize}
  \item Separable projection
  \begin{equation*}
   \prod_\mathcal{D}(\BOLD{z})=
   \begin{pmatrix}
    \prod_{\mathcal{D}_1}(T_1\BOLD{x}) \\
    \vdots \\
    \prod_{\mathcal{D}_m}(T_m\BOLD{x})
   \end{pmatrix}
  \end{equation*}
  \item Compute $\prod_{\mathcal{D}_j}(T_j\BOLD{x})=\prod_{\mathcal{D}^K}(T_j\BOLD{x})$
  \item Let $C=U\diag(\sigma_1, \dots, \sigma_d)V^T$ with $\sigma_1\ge \dots \ge \sigma_{d-1} \ge |\sigma_d|$
  \visible<1> {
  \begin{equation*}
  \boxed{
  \begin{aligned}
   &\prod_{\mathcal{D}^K}(C) = U\diag(\tau^*_1, \dots, \tau^*_d)V^T \\
   &\{\tau^*_i\} = \argmin_{\{\tau_i\}}\sum_{i=1}^d(\sigma_i-\tau_i)^2 \\
   &\ST ~~\tau_1 \le K\tau_d
  \end{aligned}}
  \end{equation*}
  }
  \pause
  \TikzDraw {
    \visible<2> { 
      \node at (-1.2, -2.25) {$\boxed{\|\prod_\mathcal{D}(\BOLD{z})\|_2 \le \|\BOLD{z}\|_2}$ };
      \node at (2, -2.5) {\includegraphics[scale=0.2]{img/proj}};
    }
  }
 \end{itemize}
 %\gridlines
\end{frame}

\begin{frame}
 \frametitle{Hyperplane}
 \begin{itemize}
  \item The proxy hyperplane
    \begin{itemize}
     \item[-] Passes through the projection $\prod_\mathcal{D}(\BOLD{z}_0)$.
     \item[-] Orthogonal to the projection direction $\BOLD{n}_0=\BOLD{z}_0-\prod_\mathcal{D}(\BOLD{z}_0)$.
    \end{itemize}
  \item 
  \begin{equation*}
    \boxed{
    T\BOLD{x}\in \mathcal{H}_0 \Rightarrow \BOLD{n}_0^T(T\BOLD{x}-\prod_\mathcal{D}(T\BOLD{x}_0)) = 0
    }
  \end{equation*}
  \visible<1>{\item $\mathcal{H}$ provides a good linear proxy for $\mathcal{D}$ at $\prod_\mathcal{D}(\BOLD{z})$ with tangent-like properties. \TODO{HOW GOOD?}}
  \pause
  \TikzDraw {
    \visible<2>{
      \node at (-1.2, -2.6) {\parbox{0.8\textwidth}{
	\begin{equation*}
	\boxed{
	 \begin{aligned}
	   &<\BOLD{n}_0, \BOLDG{\xi}> \le 0 \\
	   &\quad\BOLDG{\xi} = \gamma_+^{\prime}(0)
	 \end{aligned}}
	\end{equation*}
      }};
      \node at (1.5, -2.7) {\includegraphics[scale=0.2]{img/hyper}};
    }
  }
 \end{itemize}

\end{frame}

\begin{frame}
 \frametitle{Optimize: a linear solve}
 \begin{itemize}
  \item Iteration $\Rightarrow$ solving a \textit{linearly constrained least squares problem}
  \item KKT linear system 
  \begin{equation*}
   \begin{pmatrix}
    T^TT & A^T & T^T\BOLD{n}_0 \\
    A & 0 & 0 \\
    \BOLD{n}_0^TT & 0 & 0
   \end{pmatrix}
   \begin{pmatrix}
    \BOLD{x} \\
    \BOLDG{\lambda} \\
    \mu
   \end{pmatrix}
   =
   \begin{pmatrix}
    T^TT\BOLD{x}_0 \\
    \BOLD{b} \\
    \BOLD{n}_0^T\prod_\mathcal{D}(\BOLD{z}_0)
   \end{pmatrix}
  \end{equation*}
  \pause
  \item Schur complement
  \begin{equation*}
   \BOLDG{\eta}_0M^{-1}\BOLDG{\eta}_0\mu = -d_0+\BOLDG{\eta}_0M^{-1}\BOLD{c}_0
  \end{equation*}
  \TODO{Only need two back-substitutions}
 \end{itemize}
 \TikzDraw {
  \visible<2>{
    \draw[dashed, red, very thick](-3.2, 0.35)--(0, 0.35);
    \draw[dashed, red, very thick](0.4, 0.35)--(1.1, 0.35);
    \draw[dashed, red, very thick](1.8, 0.35)--(4.1, 0.35);
    \draw[dashed, red, very thick](-1.3, 1.3)--(-1.3, -0.2);
    \node at (-2.18, 0.75) {\TODO{$M$}};
    \node at (-0.6, 0.75) {\TODO{$\BOLDG{\eta}_0$}};
    \node at (-2.18, 0.1) {\TODO{$\BOLDG{\eta}^T_0$}};
    \node at (3, 0.75) {\TODO{$\BOLD{c}_0$}};
    \node at (3, 0.1) {\TODO{$d_0$}};
  }
 }
 %\gridlines
\end{frame}

\begin{frame}
 \frametitle{Evaluation: performance}
 \begin{figure}
  \centering
  \includegraphics[width=10cm, height=5cm]{img/performance.png}
 \end{figure}
\end{frame}

\begin{frame}
 \frametitle{Evaluation: scalability}
 \begin{figure}[t]
  \centering  
  \begin{minipage}[t][0.9\textheight][s]{1\textwidth}
    \centering
    \includegraphics[scale=0.35]{img/sc0.png} 
    \vfill
    \includegraphics[scale=0.35]{img/sc1.png}
  \end{minipage}
 \end{figure}
\end{frame}

\begin{frame}
 \frametitle{Evaluation: robustness}
 \begin{figure}[t]
  \centering
  \includegraphics[width=9cm, height=8cm]{img/robustness.png}
 \end{figure}
\end{frame}

\begin{frame}
 \frametitle{More examples}
\end{frame}

\begin{frame}
 \frametitle{Conclusion}
 \begin{itemize}
  \item Pros:
    \begin{itemize}
      \item[-] Key: single linear hyperplane $\overset{\text{local}}{\approx}$ set of BD maps
      \item[-] Comparable computational efficiency to that of alternating optimization
      \item[-] improved convergence properties 
    \end{itemize}
  \item Cons:
    \begin{itemize}
      \item[-] Lacks global convergence guarantees
      \item[-] Limited to mappings satisfying bounds on distortion
  \end{itemize}
 \end{itemize}
\end{frame}

\begin{frame} 
  \TikzDraw {
    \node at (0, 0.5) {\Huge{Thanks!}};
  }
  %\gridlines
\end{frame}


\end{document}
